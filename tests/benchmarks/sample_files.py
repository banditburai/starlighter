"""
Sample Python files for performance benchmarking.

This module generates realistic Python code samples of various sizes
and complexities for comprehensive performance testing.
"""


def generate_small_file(lines: int = 75) -> str:
    """Generate a small Python file (50-100 lines)."""
    code_lines = [
        "#!/usr/bin/env python3",
        '"""Small Python module for testing."""',
        "",
        "import os",
        "import sys",
        "from typing import List, Optional",
        "",
        "class SimpleProcessor:",
        '    """Simple data processor class."""',
        "",
        "    def __init__(self, name: str):",
        "        self.name = name",
        "        self.data = []",
        "",
        "    def add_item(self, item: str) -> bool:",
        '        """Add an item to the processor."""',
        "        if item and isinstance(item, str):",
        "            self.data.append(item.strip())",
        "            return True",
        "        return False",
        "",
        "    def process(self) -> List[str]:",
        '        """Process all items and return results."""',
        "        results = []",
        "        for item in self.data:",
        "            # Basic processing logic",
        "            processed = item.upper().replace(' ', '_')",
        "            if len(processed) > 3:",
        "                results.append(f'PROCESSED_{processed}')",
        "        return results",
        "",
        "def main():",
        '    """Main function."""',
        "    processor = SimpleProcessor('test')",
        "    processor.add_item('hello world')",
        "    processor.add_item('python testing')",
        "    results = processor.process()",
        "    for result in results:",
        "        print(result)",
        "",
        "if __name__ == '__main__':",
        "    main()",
    ]

    # Add more lines to reach target
    method_count = 1
    while len(code_lines) < lines:
        code_lines.extend(
            [
                "",
                f"    def method_{method_count}(self, param: int = 0):",
                f'        """Method {method_count} for testing."""',
                f"        result = param * {method_count}",
                "        if result > 10:",
                "            return f'High_{result}'",
                "        return f'Low_{result}'",
            ]
        )
        method_count += 1

    return "\n".join(code_lines[:lines])


def generate_medium_file(lines: int = 250) -> str:
    """Generate a medium Python file (200-300 lines)."""
    code_lines = [
        "#!/usr/bin/env python3",
        '"""',
        "Medium Python module demonstrating various language features.",
        "",
        "This module includes classes, functions, decorators, context managers,",
        "and other Python constructs for realistic performance testing.",
        '"""',
        "",
        "import os",
        "import sys",
        "import json",
        "import time",
        "import functools",
        "import contextlib",
        "from typing import List, Dict, Optional, Union, Callable, Any",
        "from dataclasses import dataclass, field",
        "from pathlib import Path",
        "",
        "@dataclass",
        "class DataRecord:",
        '    """Data record with validation."""',
        "    name: str",
        "    value: float",
        "    metadata: Dict[str, Any] = field(default_factory=dict)",
        "    created_at: float = field(default_factory=time.time)",
        "",
        "    def __post_init__(self):",
        "        if not self.name:",
        "            raise ValueError('Name cannot be empty')",
        "        if self.value < 0:",
        "            raise ValueError('Value must be non-negative')",
        "",
        "def timing_decorator(func: Callable) -> Callable:",
        '    """Decorator to measure function execution time."""',
        "    @functools.wraps(func)",
        "    def wrapper(*args, **kwargs):",
        "        start_time = time.perf_counter()",
        "        try:",
        "            result = func(*args, **kwargs)",
        "            return result",
        "        finally:",
        "            end_time = time.perf_counter()",
        "            duration = end_time - start_time",
        "            print(f'{func.__name__} took {duration:.4f}s')",
        "    return wrapper",
        "",
        "@contextlib.contextmanager",
        "def file_processor(filename: str):",
        '    """Context manager for file processing."""',
        "    print(f'Opening file: {filename}')",
        "    try:",
        "        with open(filename, 'r') as f:",
        "            yield f",
        "    except FileNotFoundError:",
        "        print(f'File not found: {filename}')",
        "        yield None",
        "    finally:",
        "        print(f'File processing complete: {filename}')",
        "",
        "class AdvancedProcessor:",
        '    """Advanced data processing with multiple algorithms."""',
        "",
        "    def __init__(self, config: Dict[str, Any]):",
        "        self.config = config",
        "        self.records: List[DataRecord] = []",
        "        self._cache: Dict[str, Any] = {}",
        "",
        "    @property",
        "    def record_count(self) -> int:",
        '        """Get the number of records."""',
        "        return len(self.records)",
        "",
        "    @timing_decorator",
        "    def add_record(self, name: str, value: float, **metadata) -> bool:",
        '        """Add a new record with validation."""',
        "        try:",
        "            record = DataRecord(name, value, metadata)",
        "            self.records.append(record)",
        "            return True",
        "        except ValueError as e:",
        "            print(f'Invalid record: {e}')",
        "            return False",
        "",
        "    def filter_records(self, predicate: Callable[[DataRecord], bool]) -> List[DataRecord]:",
        '        """Filter records using a predicate function."""',
        "        return [record for record in self.records if predicate(record)]",
        "",
        "    def aggregate_values(self, operation: str = 'sum') -> float:",
        '        """Aggregate record values using specified operation."""',
        "        if not self.records:",
        "            return 0.0",
        "",
        "        values = [record.value for record in self.records]",
        "",
        "        operations = {",
        "            'sum': sum,",
        "            'min': min,",
        "            'max': max,",
        "            'avg': lambda x: sum(x) / len(x),",
        "        }",
        "",
        "        if operation not in operations:",
        "            raise ValueError(f'Unknown operation: {operation}')",
        "",
        "        return operations[operation](values)",
        "",
        "    async def async_process(self) -> Dict[str, Any]:",
        '        """Asynchronous processing method."""',
        "        import asyncio",
        "",
        "        await asyncio.sleep(0.1)  # Simulate async work",
        "",
        "        results = {",
        "            'total_records': self.record_count,",
        "            'sum_values': self.aggregate_values('sum'),",
        "            'avg_values': self.aggregate_values('avg'),",
        "        }",
        "",
        "        return results",
    ]

    # Add more methods to reach target line count
    method_count = 1
    while len(code_lines) < lines - 20:  # Leave room for main function
        code_lines.extend(
            [
                "",
                f"    def process_method_{method_count}(self, data: List[Any]) -> List[Any]:",
                f'        """Process method {method_count} with complex logic."""',
                "        results = []",
                "        for i, item in enumerate(data):",
                f"            if i % {method_count + 1} == 0:",
                "                # Complex processing logic",
                "                processed = str(item).upper()",
                f"                if len(processed) > {method_count}:",
                "                    results.append({",
                "                        'index': i,",
                "                        'value': processed,",
                f"                        'method': {method_count},",
                "                        'timestamp': time.time(),",
                "                    })",
                "        return results",
            ]
        )
        method_count += 1

    # Add main function
    code_lines.extend(
        [
            "",
            "def main():",
            '    """Main function demonstrating usage."""',
            "    config = {'debug': True, 'max_records': 1000}",
            "    processor = AdvancedProcessor(config)",
            "",
            "    # Add sample records",
            "    sample_data = [",
            "        ('alpha', 10.5, {'category': 'A'}),",
            "        ('beta', 20.3, {'category': 'B'}),",
            "        ('gamma', 15.7, {'category': 'A'}),",
            "    ]",
            "",
            "    for name, value, meta in sample_data:",
            "        processor.add_record(name, value, **meta)",
            "",
            "    # Process data",
            "    high_value_records = processor.filter_records(",
            "        lambda r: r.value > 15.0",
            "    )",
            "",
            "    print(f'High value records: {len(high_value_records)}')",
            "    print(f'Total value sum: {processor.aggregate_values()}')",
            "",
            "if __name__ == '__main__':",
            "    main()",
        ]
    )

    return "\n".join(code_lines[:lines])


def generate_large_file(lines: int = 500) -> str:
    """Generate a large Python file (500+ lines)."""
    code_lines = [
        "#!/usr/bin/env python3",
        '"""',
        "Large Python module with comprehensive feature coverage.",
        "",
        "This module demonstrates a complete Python application with:",
        "- Multiple classes and inheritance",
        "- Async/await patterns",
        "- Context managers and decorators",
        "- Type hints and generics",
        "- Error handling and logging",
        "- File I/O and data processing",
        "- Unit testing patterns",
        '"""',
        "",
        "import os",
        "import sys",
        "import json",
        "import time",
        "import asyncio",
        "import logging",
        "import functools",
        "import contextlib",
        "import threading",
        "import multiprocessing",
        "from abc import ABC, abstractmethod",
        "from typing import (",
        "    List, Dict, Optional, Union, Callable, Any, Generic, TypeVar,",
        "    Protocol, Iterator, AsyncIterator, Awaitable",
        ")",
        "from dataclasses import dataclass, field",
        "from pathlib import Path",
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor",
        "from collections import defaultdict, Counter",
        "import unittest",
        "from unittest.mock import Mock, patch",
        "",
        "# Type variables for generics",
        "T = TypeVar('T')",
        "K = TypeVar('K')",
        "V = TypeVar('V')",
        "",
        "# Configure logging",
        "logging.basicConfig(",
        "    level=logging.INFO,",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'",
        ")",
        "logger = logging.getLogger(__name__)",
        "",
        "class ProcessorProtocol(Protocol):",
        '    """Protocol for data processors."""',
        "    def process(self, data: Any) -> Any:",
        "        ...",
        "",
        "    def validate(self, data: Any) -> bool:",
        "        ...",
        "",
        "@dataclass",
        "class ProcessingResult(Generic[T]):",
        '    """Generic result container."""',
        "    data: T",
        "    success: bool",
        "    error: Optional[str] = None",
        "    metadata: Dict[str, Any] = field(default_factory=dict)",
        "    processing_time: float = 0.0",
        "",
        "class BaseProcessor(ABC, Generic[T]):",
        '    """Abstract base processor class."""',
        "",
        "    def __init__(self, name: str, config: Dict[str, Any]):",
        "        self.name = name",
        "        self.config = config",
        "        self.stats = Counter()",
        "        self._lock = threading.Lock()",
        "",
        "    @abstractmethod",
        "    def process(self, data: T) -> ProcessingResult[T]:",
        '        """Process data and return result."""',
        "        pass",
        "",
        "    @abstractmethod",
        "    def validate(self, data: T) -> bool:",
        '        """Validate input data."""',
        "        pass",
        "",
        "    def update_stats(self, key: str, count: int = 1):",
        '        """Thread-safe stats update."""',
        "        with self._lock:",
        "            self.stats[key] += count",
        "",
        "class TextProcessor(BaseProcessor[str]):",
        '    """Text processing implementation."""',
        "",
        "    def __init__(self, name: str, config: Dict[str, Any]):",
        "        super().__init__(name, config)",
        "        self.min_length = config.get('min_length', 1)",
        "        self.max_length = config.get('max_length', 1000)",
        "",
        "    def validate(self, data: str) -> bool:",
        '        """Validate text data."""',
        "        if not isinstance(data, str):",
        "            return False",
        "        return self.min_length <= len(data) <= self.max_length",
        "",
        "    def process(self, data: str) -> ProcessingResult[str]:",
        '        """Process text data."""',
        "        start_time = time.perf_counter()",
        "",
        "        try:",
        "            if not self.validate(data):",
        "                return ProcessingResult(",
        "                    data=data,",
        "                    success=False,",
        "                    error='Validation failed',",
        "                    processing_time=time.perf_counter() - start_time",
        "                )",
        "",
        "            # Text processing logic",
        "            processed_data = data.strip().lower()",
        "            processed_data = ' '.join(processed_data.split())",
        "",
        "            self.update_stats('processed')",
        "            ",
        "            return ProcessingResult(",
        "                data=processed_data,",
        "                success=True,",
        "                processing_time=time.perf_counter() - start_time,",
        "                metadata={'original_length': len(data), 'processed_length': len(processed_data)}",
        "            )",
        "",
        "        except Exception as e:",
        "            self.update_stats('errors')",
        "            return ProcessingResult(",
        "                data=data,",
        "                success=False,",
        "                error=str(e),",
        "                processing_time=time.perf_counter() - start_time",
        "            )",
    ]

    # Add methods to reach target line count but not exceed it
    class_count = 1
    while (
        len(code_lines) < lines - 30 and class_count <= 3
    ):  # Limit classes to prevent overshooting
        code_lines.extend(
            [
                "",
                f"class DataProcessor{class_count}(BaseProcessor[Dict[str, Any]]):",
                f'    """Data processor {class_count} with specialized logic."""',
                "",
                "    def __init__(self, name: str, config: Dict[str, Any]):",
                "        super().__init__(name, config)",
                "        self.schema = config.get('schema', {})",
                "        self.transformations = config.get('transformations', [])",
                "",
                "    def validate(self, data: Dict[str, Any]) -> bool:",
                '        """Validate data against schema."""',
                "        if not isinstance(data, dict):",
                "            return False",
                "        ",
                "        for key, value_type in self.schema.items():",
                "            if key not in data:",
                "                return False",
                "            if not isinstance(data[key], value_type):",
                "                return False",
                "        ",
                "        return True",
                "",
                "    def process(self, data: Dict[str, Any]) -> ProcessingResult[Dict[str, Any]]:",
                '        """Process dictionary data."""',
                "        start_time = time.perf_counter()",
                "        ",
                "        try:",
                "            if not self.validate(data):",
                "                return ProcessingResult(",
                "                    data=data,",
                "                    success=False,",
                "                    error='Schema validation failed',",
                "                    processing_time=time.perf_counter() - start_time",
                "                )",
                "            ",
                "            # Apply transformations",
                "            processed_data = data.copy()",
                "            for transform in self.transformations:",
                "                if transform == 'normalize':",
                "                    processed_data = self._normalize(processed_data)",
                "                elif transform == 'aggregate':",
                "                    processed_data = self._aggregate(processed_data)",
                "                elif transform == 'filter':",
                "                    processed_data = self._filter(processed_data)",
                "            ",
                "            self.update_stats('processed')",
                "            ",
                "            return ProcessingResult(",
                "                data=processed_data,",
                "                success=True,",
                "                processing_time=time.perf_counter() - start_time",
                "            )",
                "        ",
                "        except Exception as e:",
                "            self.update_stats('errors')",
                "            return ProcessingResult(",
                "                data=data,",
                "                success=False,",
                "                error=str(e),",
                "                processing_time=time.perf_counter() - start_time",
                "            )",
                "",
                "    def _normalize(self, data: Dict[str, Any]) -> Dict[str, Any]:",
                '        """Normalize data values."""',
                "        normalized = {}",
                "        for key, value in data.items():",
                "            if isinstance(value, str):",
                "                normalized[key] = value.strip().lower()",
                "            elif isinstance(value, (int, float)):",
                "                normalized[key] = float(value)",
                "            else:",
                "                normalized[key] = value",
                "        return normalized",
                "",
                "    def _aggregate(self, data: Dict[str, Any]) -> Dict[str, Any]:",
                '        """Aggregate numeric values."""',
                "        numeric_values = [v for v in data.values() if isinstance(v, (int, float))]",
                "        if numeric_values:",
                "            data['_sum'] = sum(numeric_values)",
                "            data['_avg'] = sum(numeric_values) / len(numeric_values)",
                "            data['_min'] = min(numeric_values)",
                "            data['_max'] = max(numeric_values)",
                "        return data",
                "",
                "    def _filter(self, data: Dict[str, Any]) -> Dict[str, Any]:",
                '        """Filter out None values and empty strings."""',
                "        return {k: v for k, v in data.items() ",
                "                if v is not None and v != ''}",
            ]
        )
        class_count += 1

    # Add async methods and main function
    code_lines.extend(
        [
            "",
            "async def async_process_batch(processor: BaseProcessor, batch: List[Any]) -> List[ProcessingResult]:",
            '    """Asynchronously process a batch of items."""',
            "    tasks = []",
            "    ",
            "    for item in batch:",
            "        # Create async task for each item",
            "        task = asyncio.create_task(_async_process_item(processor, item))",
            "        tasks.append(task)",
            "    ",
            "    results = await asyncio.gather(*tasks, return_exceptions=True)",
            "    ",
            "    # Handle exceptions",
            "    processed_results = []",
            "    for result in results:",
            "        if isinstance(result, Exception):",
            "            processed_results.append(ProcessingResult(",
            "                data=None,",
            "                success=False,",
            "                error=str(result)",
            "            ))",
            "        else:",
            "            processed_results.append(result)",
            "    ",
            "    return processed_results",
            "",
            "async def _async_process_item(processor: BaseProcessor, item: Any) -> ProcessingResult:",
            '    """Process a single item asynchronously."""',
            "    # Simulate async processing",
            "    await asyncio.sleep(0.001)",
            "    return processor.process(item)",
            "",
            "class ProcessorManager:",
            '    """Manager for multiple processors with load balancing."""',
            "",
            "    def __init__(self):",
            "        self.processors: Dict[str, BaseProcessor] = {}",
            "        self.executor = ThreadPoolExecutor(max_workers=4)",
            "",
            "    def register_processor(self, name: str, processor: BaseProcessor):",
            '        """Register a processor."""',
            "        self.processors[name] = processor",
            "",
            "    def process_parallel(self, data_items: List[Tuple[str, Any]]) -> List[ProcessingResult]:",
            '        """Process items in parallel using registered processors."""',
            "        futures = []",
            "        ",
            "        for processor_name, data in data_items:",
            "            if processor_name in self.processors:",
            "                processor = self.processors[processor_name]",
            "                future = self.executor.submit(processor.process, data)",
            "                futures.append(future)",
            "        ",
            "        results = []",
            "        for future in futures:",
            "            try:",
            "                result = future.result(timeout=10.0)",
            "                results.append(result)",
            "            except Exception as e:",
            "                results.append(ProcessingResult(",
            "                    data=None,",
            "                    success=False,",
            "                    error=str(e)",
            "                ))",
            "        ",
            "        return results",
            "",
            "    def shutdown(self):",
            '        """Shutdown the manager."""',
            "        self.executor.shutdown(wait=True)",
            "",
            "def main():",
            '    """Main function demonstrating all features."""',
            "    logger.info('Starting complex processing application')",
            "    ",
            "    # Create processors",
            "    text_config = {'min_length': 5, 'max_length': 500}",
            "    text_processor = TextProcessor('text_proc', text_config)",
            "    ",
            "    data_config = {",
            "        'schema': {'name': str, 'value': float},",
            "        'transformations': ['normalize', 'aggregate']",
            "    }",
            "    data_processor = DataProcessor1('data_proc', data_config)",
            "    ",
            "    # Create manager",
            "    manager = ProcessorManager()",
            "    manager.register_processor('text', text_processor)",
            "    manager.register_processor('data', data_processor)",
            "    ",
            "    # Test data",
            "    test_items = [",
            "        ('text', 'Hello World Processing Test'),",
            "        ('data', {'name': 'test', 'value': 42.5}),",
            "        ('text', 'Another text sample for processing'),",
            "    ]",
            "    ",
            "    # Process in parallel",
            "    results = manager.process_parallel(test_items)",
            "    ",
            "    # Display results",
            "    for i, result in enumerate(results):",
            "        logger.info(f'Result {i}: Success={result.success}, Time={result.processing_time:.4f}s')",
            "        if not result.success:",
            "            logger.error(f'Error: {result.error}')",
            "    ",
            "    manager.shutdown()",
            "    logger.info('Application completed')",
            "",
            "if __name__ == '__main__':",
            "    main()",
        ]
    )

    return "\n".join(code_lines[:lines])


def generate_mixed_starhtml_file(lines: int = 300) -> str:
    """Generate a file with mixed Python and StarHTML syntax."""
    code_lines = [
        "#!/usr/bin/env python3",
        '"""',
        "StarHTML/DataStar integration example for performance testing.",
        '"""',
        "",
        "from typing import List, Dict, Any",
        "import json",
        "",
        "# StarHTML component definitions",
        "def create_header(title: str, level: int = 1) -> str:",
        '    """Create a header component."""',
        "    if level == 1:",
        "        return H1[title]",
        "    elif level == 2:",
        "        return H2[title]",
        "    else:",
        "        return H3[title]",
        "",
        "def create_button(text: str, onclick: str = '') -> str:",
        '    """Create a button with DataStar integration."""',
        "    return Button[",
        "        text,",
        "        data_on_click=onclick,",
        "        data_show='visible',",
        "        class_='btn btn-primary'",
        "    ]",
        "",
        "def create_form(fields: List[Dict[str, Any]]) -> str:",
        '    """Create a form with multiple fields."""',
        "    form_content = []",
        "    ",
        "    for field in fields:",
        "        field_type = field.get('type', 'text')",
        "        field_name = field.get('name', '')",
        "        field_label = field.get('label', field_name)",
        "        ",
        "        # Create label",
        "        label = Label[field_label, for_=field_name]",
        "        form_content.append(label)",
        "        ",
        "        # Create input based on type",
        "        if field_type == 'text':",
        "            input_field = Input[",
        "                type='text',",
        "                name=field_name,",
        "                data_model=f'form.{field_name}',",
        "                data_validate='required'",
        "            ]",
        "        elif field_type == 'textarea':",
        "            input_field = Textarea[",
        "                '',",
        "                name=field_name,",
        "                data_model=f'form.{field_name}',",
        "                rows='4'",
        "            ]",
        "        else:",
        "            input_field = Input[type=field_type, name=field_name]",
        "        ",
        "        form_content.append(input_field)",
        "    ",
        "    # Create submit button",
        "    submit_btn = create_button(",
        "        'Submit',",
        "        onclick='submitForm()'",
        "    )",
        "    form_content.append(submit_btn)",
        "    ",
        "    return Form[*form_content, method='post', data_on_submit='handleSubmit']",
        "",
        "def create_data_table(data: List[Dict[str, Any]], columns: List[str]) -> str:",
        '    """Create a data table with StarHTML."""',
        "    # Create header row",
        "    header_cells = [Th[col] for col in columns]",
        "    header_row = Tr[*header_cells]",
        "    ",
        "    # Create data rows",
        "    data_rows = []",
        "    for row_data in data:",
        "        cells = []",
        "        for col in columns:",
        "            cell_value = row_data.get(col, '')",
        "            if isinstance(cell_value, (int, float)):",
        "                cell = Td[str(cell_value), class_='numeric']",
        "            else:",
        "                cell = Td[str(cell_value)]",
        "            cells.append(cell)",
        "        data_rows.append(Tr[*cells])",
        "    ",
        "    return Table[",
        "        Thead[header_row],",
        "        Tbody[*data_rows],",
        "        class_='table table-striped',",
        "        data_sortable='true'",
        "    ]",
        "",
        "class PageBuilder:",
        '    """Build complete pages with StarHTML."""',
        "",
        "    def __init__(self, title: str):",
        "        self.title = title",
        "        self.components = []",
        "        self.scripts = []",
        "        self.styles = []",
        "",
        "    def add_component(self, component: str):",
        '        """Add a component to the page."""',
        "        self.components.append(component)",
        "",
        "    def add_script(self, script_url: str):",
        '        """Add a script to the page."""',
        "        self.scripts.append(script_url)",
        "",
        "    def add_style(self, style_url: str):",
        '        """Add a stylesheet to the page."""',
        "        self.styles.append(style_url)",
        "",
        "    def build_head(self) -> str:",
        '        """Build the head section."""',
        "        head_content = [",
        "            Meta[charset='utf-8'],",
        "            Meta[name='viewport', content='width=device-width, initial-scale=1'],",
        "            Title[self.title]",
        "        ]",
        "        ",
        "        # Add stylesheets",
        "        for style in self.styles:",
        "            head_content.append(",
        "                Link[rel='stylesheet', href=style]",
        "            )",
        "        ",
        "        return Head[*head_content]",
        "",
        "    def build_body(self) -> str:",
        '        """Build the body section."""',
        "        body_content = [",
        "            Header[",
        "                create_header(self.title),",
        "                Nav[",
        "                    Ul[",
        "                        Li[A['Home', href='/']],",
        "                        Li[A['About', href='/about']],",
        "                        Li[A['Contact', href='/contact']]",
        "                    ]",
        "                ]",
        "            ],",
        "            Main[*self.components, id='main-content']",
        "        ]",
        "        ",
        "        # Add scripts",
        "        for script in self.scripts:",
        "            body_content.append(",
        "                Script[src=script, defer=True]",
        "            )",
        "        ",
        "        return Body[*body_content]",
        "",
        "    def build(self) -> str:",
        '        """Build the complete page."""',
        "        return Html[",
        "            self.build_head(),",
        "            self.build_body(),",
        "            lang='en',",
        "            data_theme='light'",
        "        ]",
    ]

    # Add more methods to reach target lines
    method_count = 1
    while len(code_lines) < lines - 50:
        code_lines.extend(
            [
                "",
                f"    def create_section_{method_count}(self, content: List[str]) -> str:",
                f'        """Create section {method_count} with dynamic content."""',
                "        section_items = []",
                "        ",
                "        for i, item in enumerate(content):",
                "            if i % 2 == 0:",
                "                section_items.append(",
                "                    Div[",
                "                        P[item],",
                "                        class_=f'content-item-{i}',",
                "                        data_index=str(i),",
                "                        data_content_type='text'",
                "                    ]",
                "                )",
                "            else:",
                "                section_items.append(",
                "                    Div[",
                "                        Strong[item],",
                "                        class_='highlighted',",
                "                        data_highlight='true'",
                "                    ]",
                "                )",
                "        ",
                "        return Section[",
                "            create_header(f'Section {method_count}', level=2),",
                "            *section_items,",
                "            id=f'section-{method_count}',",
                f"            data_section_id=str({method_count})",
                "        ]",
            ]
        )
        method_count += 1

    # Add main function
    code_lines.extend(
        [
            "",
            "def main():",
            '    """Main function demonstrating StarHTML usage."""',
            "    # Create page builder",
            "    builder = PageBuilder('StarHTML Performance Test')",
            "    builder.add_style('/static/css/bootstrap.min.css')",
            "    builder.add_script('/static/js/datastar.js')",
            "    ",
            "    # Create form",
            "    form_fields = [",
            "        {'type': 'text', 'name': 'username', 'label': 'Username'},",
            "        {'type': 'email', 'name': 'email', 'label': 'Email'},",
            "        {'type': 'textarea', 'name': 'message', 'label': 'Message'}",
            "    ]",
            "    contact_form = create_form(form_fields)",
            "    builder.add_component(contact_form)",
            "    ",
            "    # Create data table",
            "    sample_data = [",
            "        {'name': 'Alice', 'age': 30, 'city': 'New York'},",
            "        {'name': 'Bob', 'age': 25, 'city': 'San Francisco'},",
            "        {'name': 'Charlie', 'age': 35, 'city': 'Chicago'}",
            "    ]",
            "    table = create_data_table(sample_data, ['name', 'age', 'city'])",
            "    builder.add_component(table)",
            "    ",
            "    # Build and return page",
            "    page_html = builder.build()",
            "    print('StarHTML page generated successfully')",
            "    return page_html",
            "",
            "if __name__ == '__main__':",
            "    main()",
        ]
    )

    return "\n".join(code_lines[:lines])


def generate_stress_test_file(lines: int = 1000) -> str:
    """Generate a very large file for stress testing."""
    code = generate_large_file(500)  # Start with large file

    # Add more repetitive content to reach target
    additional_lines = []
    class_num = 10

    while len(code.split("\n")) + len(additional_lines) < lines:
        additional_lines.extend(
            [
                "",
                f"class StressTestClass{class_num}:",
                f'    """Stress test class {class_num} for performance validation."""',
                "",
                "    def __init__(self, data: Dict[str, Any]):",
                "        self.data = data",
                "        self.processed_count = 0",
                "",
                f"    def process_data_{class_num}(self, items: List[Any]) -> List[Any]:",
                f'        """Process data method {class_num}."""',
                "        results = []",
                "        for i, item in enumerate(items):",
                "            try:",
                "                if isinstance(item, str):",
                "                    processed = item.upper().replace(' ', '_')",
                f"                    results.append(f'STR_{class_num}_{{processed}}')",
                "                elif isinstance(item, (int, float)):",
                f"                    processed = item * {class_num}",
                f"                    results.append(f'NUM_{class_num}_{{processed}}')",
                "                else:",
                f"                    results.append(f'OTHER_{class_num}_{{str(item)}}')",
                "                self.processed_count += 1",
                "            except Exception as e:",
                f"                results.append(f'ERROR_{class_num}_{{str(e)}}')",
                "        return results",
            ]
        )
        class_num += 1

    return code + "\n" + "\n".join(additional_lines[: lines - len(code.split("\n"))])


# Test file generators mapping
TEST_FILE_GENERATORS = {
    "small": generate_small_file,
    "medium": generate_medium_file,
    "large": generate_large_file,
    "mixed_starhtml": generate_mixed_starhtml_file,
    "stress": generate_stress_test_file,
}
